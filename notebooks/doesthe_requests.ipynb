{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df = pd.read_csv('../data/local/clean/movie_sample_pre19.csv')\n",
    "sample_df = pd.read_csv('../data/local/raw/pending_letterboxd_films_for_request.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rquest to extract ID and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY_DOESTHEDOGDIE = os.getenv(\"API_KEY_DOESTHEDOGDIE\")\n",
    "\n",
    "BASE_URL = \"https://www.doesthedogdie.com/dddsearch?q=\"\n",
    "\n",
    "# extract topics of interest from the 'stats' field\n",
    "def extract_topics(stats_str):\n",
    "    try:\n",
    "        stats = json.loads(stats_str)  # stats is a string, so we parse it into a dictionary\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding stats:\", stats_str)\n",
    "        return \"\"\n",
    "    \n",
    "    if 'topics' not in stats:\n",
    "        print(\"No 'topics' field in response:\", stats)  # response stats\n",
    "        return \"\"\n",
    "    \n",
    "    # get topics where 'definitelyYes' > 'definitelyNo', and both are greater than 1\n",
    "    topics_of_interest = []\n",
    "    \n",
    "    for topic_id, data in stats['topics'].items():\n",
    "        definitely_yes = int(data['definitelyYes'])\n",
    "        definitely_no = int(data['definitelyNo'])\n",
    "        \n",
    "        if definitely_yes > definitely_no:\n",
    "            topics_of_interest.append(str(topic_id)) \n",
    "    \n",
    "    return \",\".join(topics_of_interest)  # join topics w comma\n",
    "\n",
    "# process in batches\n",
    "def process_in_batches(df, batch_size=50):\n",
    "    df['topics'] = None\n",
    "    df['doesthedog_id'] = None\n",
    "    \n",
    "    responses = []\n",
    "    \n",
    "    for start in range(0, len(df), batch_size):  \n",
    "        end = min(start + batch_size, len(df))  # define batch end\n",
    "        batch = df.iloc[start:end]\n",
    "        \n",
    "        current_responses = []\n",
    "        \n",
    "        for title in batch['title']:\n",
    "            url = f\"{BASE_URL}{title}\"\n",
    "            headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"X-API-KEY\": API_KEY_DOESTHEDOGDIE,\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                current_responses.append(response.json())\n",
    "            else:\n",
    "                print(f\"Error with request for {title}: {response.status_code}\")\n",
    "        \n",
    "        responses.extend(current_responses)\n",
    "        \n",
    "        for index, response in enumerate(current_responses):\n",
    "            items = response.get('items', [])\n",
    "            if items:\n",
    "                stats_str = items[0].get('stats', '{}')  # get the 'stats' field\n",
    "                topics = extract_topics(stats_str)\n",
    "                \n",
    "                doesthedog_id = items[0].get('id', None)\n",
    "                \n",
    "                df.loc[start + index, 'topics'] = topics\n",
    "                df.loc[start + index, 'doesthedog_id'] = doesthedog_id\n",
    "        \n",
    "        # save to CSV after each batch, appending if the file exists\n",
    "        file_name = \"letterboxd_request_backup.csv\"\n",
    "        if os.path.exists(file_name):\n",
    "            df.iloc[start:end].to_csv(file_name, mode='a', header=False, index=False) # append new data if file exists\n",
    "        else:\n",
    "            df.iloc[start:end].to_csv(file_name, mode='w', header=True, index=False)\n",
    "        \n",
    "        time.sleep(2)  # prevent rate limiting\n",
    "    \n",
    "    return df\n",
    "\n",
    "sample_df = process_in_batches(sample_df, batch_size=50)\n",
    "\n",
    "print(sample_df[['title', 'topics', 'doesthedog_id']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
