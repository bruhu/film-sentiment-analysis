{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape missing data from doesthedogdie.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('../data/local/clean/movie_sample.csv')\n",
    "# display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request for the first five rows in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the API key from the .env file\n",
    "# load_dotenv()\n",
    "# API_KEY_DOESTHEDOGDIE = os.getenv(\"API_KEY_DOESTHEDOGDIE\")\n",
    "\n",
    "# # Sample data for demonstration purposes. Replace this with your actual DataFrame.\n",
    "# # sample_df = pd.read_csv(\"path_to_your_csv.csv\")  # Example of how you might load your DataFrame\n",
    "\n",
    "# # Define the URL for the API request\n",
    "# BASE_URL = \"https://www.doesthedogdie.com/dddsearch?q=\"\n",
    "\n",
    "# # Initialize a list to store the responses\n",
    "# responses = []\n",
    "\n",
    "# # Loop through the first 5 rows of 'clean_title' in the sample_df\n",
    "# for clean_name in sample_df['clean_title'][:5]:  # First 5 rows\n",
    "#     url = f\"{BASE_URL}{clean_name}\"\n",
    "#     headers = {\n",
    "#         \"Accept\": \"application/json\",\n",
    "#         \"X-API-KEY\": API_KEY_DOESTHEDOGDIE,\n",
    "#     }\n",
    "    \n",
    "#     # Make the GET request to the API\n",
    "#     response = requests.get(url, headers=headers)\n",
    "    \n",
    "#     if response.status_code == 200:\n",
    "#         responses.append(response.json())\n",
    "#     else:\n",
    "#         print(f\"Error with request for {clean_name}: {response.status_code}\")\n",
    "\n",
    "# # Function to extract topics of interest from the 'stats' field\n",
    "# def extract_topics(stats_str):\n",
    "#     # Convert the string into a Python dictionary\n",
    "#     try:\n",
    "#         stats = json.loads(stats_str)  # stats is a string, so we parse it into a dictionary\n",
    "#     except json.JSONDecodeError:\n",
    "#         print(\"Error decoding stats:\", stats_str)\n",
    "#         return \"\"\n",
    "    \n",
    "#     # Check if 'topics' key exists\n",
    "#     if 'topics' not in stats:\n",
    "#         print(\"No 'topics' field in response:\", stats)  # Print full response to investigate\n",
    "#         return \"\"\n",
    "    \n",
    "#     # Extract topics where 'definitelyYes' > 'definitelyNo', and both are greater than 1\n",
    "#     topics_of_interest = []\n",
    "    \n",
    "#     for topic_id, data in stats['topics'].items():\n",
    "#         definitely_yes = int(data['definitelyYes'])  # Ensure definitelyYes is an integer\n",
    "#         definitely_no = int(data['definitelyNo'])  # Ensure definitelyNo is an integer\n",
    "        \n",
    "#         # Apply condition: definitelyYes > definitelyNo and both values should be greater than 1\n",
    "#         if definitely_yes > definitely_no:\n",
    "#             topics_of_interest.append(str(topic_id))  # Store topic ID as a string\n",
    "    \n",
    "#     return \",\".join(topics_of_interest)  # Join the topics into a comma-separated string\n",
    "\n",
    "# # Add the 'topics' and 'doesthedog_id' columns to the DataFrame\n",
    "# sample_df['topics'] = None\n",
    "# sample_df['doesthedog_id'] = None\n",
    "\n",
    "# # Loop through the responses and assign topics to the 'topics' column\n",
    "# for index, response in enumerate(responses):\n",
    "#     items = response.get('items', [])\n",
    "#     if items:\n",
    "#         stats_str = items[0].get('stats', '{}')  # Get the 'stats' field for the first item\n",
    "#         topics = extract_topics(stats_str)\n",
    "        \n",
    "#         # Get the 'id' from the response (this is the 'id' field in each 'item')\n",
    "#         doesthedog_id = items[0].get('id', None)\n",
    "        \n",
    "#         # Assign the topics and id to the correct row in the DataFrame\n",
    "#         sample_df.loc[index, 'topics'] = topics\n",
    "#         sample_df.loc[index, 'doesthedog_id'] = doesthedog_id\n",
    "\n",
    "# # Display the DataFrame with the 'topics' and 'doesthedog_id' columns added (using 'clean_title' column)\n",
    "# # print(sample_df[['clean_title', 'topics', 'doesthedog_id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request in batches for the whole df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "API_KEY_DOESTHEDOGDIE = os.getenv(\"API_KEY_DOESTHEDOGDIE\")\n",
    "\n",
    "# Define the URL for the API request\n",
    "BASE_URL = \"https://www.doesthedogdie.com/dddsearch?q=\"\n",
    "\n",
    "# Function to extract topics of interest from the 'stats' field\n",
    "def extract_topics(stats_str):\n",
    "    # Convert the string into a Python dictionary\n",
    "    try:\n",
    "        stats = json.loads(stats_str)  # stats is a string, so we parse it into a dictionary\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding stats:\", stats_str)\n",
    "        return \"\"\n",
    "    \n",
    "    # Check if 'topics' key exists\n",
    "    if 'topics' not in stats:\n",
    "        print(\"No 'topics' field in response:\", stats)  # Print full response to investigate\n",
    "        return \"\"\n",
    "    \n",
    "    # Extract topics where 'definitelyYes' > 'definitelyNo', and both are greater than 1\n",
    "    topics_of_interest = []\n",
    "    \n",
    "    for topic_id, data in stats['topics'].items():\n",
    "        definitely_yes = int(data['definitelyYes'])  # Ensure definitelyYes is an integer\n",
    "        definitely_no = int(data['definitelyNo'])  # Ensure definitelyNo is an integer\n",
    "        \n",
    "        # Apply condition: definitelyYes > definitelyNo and both values should be greater than 1\n",
    "        if definitely_yes > definitely_no:\n",
    "            topics_of_interest.append(str(topic_id))  # Store topic ID as a string\n",
    "    \n",
    "    return \",\".join(topics_of_interest)  # Join the topics into a comma-separated string\n",
    "\n",
    "# Function to process the DataFrame in batches\n",
    "def process_in_batches(df, batch_size=50):\n",
    "    # Add the 'topics' and 'doesthedog_id' columns to the DataFrame\n",
    "    df['topics'] = None\n",
    "    df['doesthedog_id'] = None\n",
    "    \n",
    "    # Initialize a list to store responses\n",
    "    responses = []\n",
    "    \n",
    "    # Loop through the rows in batches\n",
    "    for start in range(0, len(df), batch_size):\n",
    "        end = min(start + batch_size, len(df))  # Define the batch end\n",
    "        batch = df.iloc[start:end]\n",
    "        \n",
    "        # Initialize a list to store the current batch's responses\n",
    "        current_responses = []\n",
    "        \n",
    "        for clean_name in batch['clean_title']:\n",
    "            url = f\"{BASE_URL}{clean_name}\"\n",
    "            headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"X-API-KEY\": API_KEY_DOESTHEDOGDIE,\n",
    "            }\n",
    "            \n",
    "            # Make the GET request to the API\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                current_responses.append(response.json())\n",
    "            else:\n",
    "                print(f\"Error with request for {clean_name}: {response.status_code}\")\n",
    "        \n",
    "        # Store the current batch responses\n",
    "        responses.extend(current_responses)\n",
    "        \n",
    "        # Save backup after each batch to ensure progress is saved\n",
    "        df_backup = df.copy()\n",
    "        for index, response in enumerate(current_responses):\n",
    "            items = response.get('items', [])\n",
    "            if items:\n",
    "                stats_str = items[0].get('stats', '{}')  # Get the 'stats' field for the first item\n",
    "                topics = extract_topics(stats_str)\n",
    "                \n",
    "                # Get the 'id' from the response (this is the 'id' field in each 'item')\n",
    "                doesthedog_id = items[0].get('id', None)\n",
    "                \n",
    "                # Assign the topics and id to the correct row in the DataFrame\n",
    "                df_backup.loc[start + index, 'topics'] = topics\n",
    "                df_backup.loc[start + index, 'doesthedog_id'] = doesthedog_id\n",
    "        \n",
    "        # Save the backup file after processing each batch\n",
    "        df_backup.to_csv(\"backup_file.csv\", index=False)\n",
    "        \n",
    "        # Sleep to avoid hitting API rate limits\n",
    "        time.sleep(2)  # Adjust the sleep time if needed to prevent rate limiting\n",
    "    \n",
    "    # Return the final DataFrame with all topics and doesthedog_id added\n",
    "    return df\n",
    "\n",
    "# Sample DataFrame (Replace with your actual DataFrame)\n",
    "# sample_df = pd.read_csv(\"path_to_your_csv.csv\")  # Example of how you might load your DataFrame\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "sample_df = process_in_batches(sample_df, batch_size=50)\n",
    "\n",
    "# Display the final DataFrame with 'topics' and 'doesthedog_id' columns added\n",
    "print(sample_df[['clean_title', 'topics', 'doesthedog_id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check 'topics' length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df['topics_length'] = sample_df['topics'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n",
    "\n",
    "# print(sample_df[['topics', 'topics_length']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
