{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import sys\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts')\n",
    "import content_tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean/clean_films_id.csv')\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = content_tagging.assign_content_tags(df)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze sentiment for each keyword separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle non-string values in the 'content_tags' column\n",
    "df['content_tags'] = df['content_tags'].fillna('')  # Replace NaN values with an empty string\n",
    "df['content_tags'] = df['content_tags'].astype(str)  # Ensure all values are strings\n",
    "\n",
    "# Split the keywords in the 'content_tags' column by commas\n",
    "df['keywords'] = df['content_tags'].apply(lambda x: x.split(','))\n",
    "\n",
    "# Function to apply sentiment analysis on each keyword\n",
    "def analyze_keywords_sentiment(keywords):\n",
    "    return [sia.polarity_scores(keyword.strip())['compound'] for keyword in keywords]\n",
    "\n",
    "# Apply sentiment analysis to each keyword in the 'keywords' list\n",
    "df['sentiment_scores'] = df['keywords'].apply(analyze_keywords_sentiment)\n",
    "\n",
    "# Calculate the average compound score for each row (optional)\n",
    "df['average_compound'] = df['sentiment_scores'].apply(lambda scores: sum(scores) / len(scores) if scores else 0)\n",
    "\n",
    "# Display the updated dataframe with sentiment scores\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all sentiment scores from the 'sentiment_scores' column into a single list\n",
    "all_sentiment_scores = [score for scores in df['sentiment_scores'] for score in scores]\n",
    "\n",
    "# Calculate the overall average sentiment score\n",
    "overall_average_sentiment = sum(all_sentiment_scores) / len(all_sentiment_scores) if all_sentiment_scores else 0\n",
    "\n",
    "# Print the overall average sentiment score\n",
    "print(f\"Overall Average Sentiment Score: {overall_average_sentiment:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of Average Compound Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plot of average compound scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['average_compound'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Average Compound Sentiment Scores', fontsize=16)\n",
    "plt.xlabel('Average Compound Sentiment Score', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar Chart of Keywords and Their Average Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords and their average sentiment scores\n",
    "keyword_sentiments = (\n",
    "    df.explode('keywords')  # Flatten the 'keywords' list\n",
    "    .groupby('keywords')['average_compound']  # Group by keyword\n",
    "    .mean()  # Calculate the average sentiment per keyword\n",
    "    .sort_values(ascending=False)  # Sort by sentiment\n",
    "    .head(10)  # Show the top 10 keywords\n",
    ")\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=keyword_sentiments.values, y=keyword_sentiments.index, palette='viridis')\n",
    "plt.title('Top 10 Keywords by Average Sentiment Score', fontsize=16)\n",
    "plt.xlabel('Average Sentiment Score', fontsize=14)\n",
    "plt.ylabel('Keywords', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap of Sentiment Scores Across Rows and Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix of rows vs. keywords\n",
    "heatmap_data = df.explode('keywords').reset_index(drop=True)  # Flatten the 'keywords' list and reset index\n",
    "\n",
    "# Add the corresponding sentiment score for each keyword\n",
    "heatmap_data['sentiment'] = heatmap_data.explode('sentiment_scores').reset_index(drop=True)['sentiment_scores']\n",
    "\n",
    "# Pivot the data for a heatmap\n",
    "heatmap_pivot = heatmap_data.pivot_table(index=heatmap_data.index, columns='keywords', values='sentiment', aggfunc='mean')\n",
    "\n",
    "# Plot the heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(heatmap_pivot, cmap='coolwarm', annot=False, cbar=True)\n",
    "plt.title('Heatmap of Sentiment Scores Across Rows and Keywords', fontsize=16)\n",
    "plt.xlabel('Keywords', fontsize=14)\n",
    "plt.ylabel('Row Index', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Trendline Across Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df['average_compound'], color='purple', label='Sentiment Trend')\n",
    "plt.title('Sentiment Trendline Across Rows', fontsize=16)\n",
    "plt.xlabel('Row Index', fontsize=14)\n",
    "plt.ylabel('Average Compound Sentiment Score', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the values in the 'events' column into a single string\n",
    "events_text = \" \".join(df['events'].dropna().astype(str))\n",
    "\n",
    "# Combine all the values in the 'content_tags' column into a single string\n",
    "content_tags_text = \" \".join(df['content_tags'].dropna().astype(str))\n",
    "\n",
    "# Create a function to generate and display a word cloud with a pink colormap\n",
    "def generate_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, height=400,\n",
    "        background_color='white',\n",
    "        colormap='spring'  # Shiny pink shades\n",
    "    ).generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16, color='hotpink')\n",
    "    plt.show()\n",
    "\n",
    "# Generate and display the word cloud for 'events'\n",
    "generate_wordcloud(events_text, 'Word Cloud for Events')\n",
    "\n",
    "# Generate and display the word cloud for 'content_tags'\n",
    "generate_wordcloud(content_tags_text, 'Word Cloud for Content Tags')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
